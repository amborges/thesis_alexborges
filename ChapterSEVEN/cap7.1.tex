\section{Metodologia e Ferramental Utilizado}
\label{cap:7.1}

Apesar de os vídeos de ultra alta definição estarem crescendo em uso, principalmente UHD4K (de 3840$\times$2160 ou 4096$\times$2160 pixels), é a resolução de alta-definição 1080 (HD1080, de 1920$\times$1080 pixels) que é a mais consumida pelos usuários de serviços de \textit{streaming} \cite{bib:bitmovin_twitter}. Portanto, nas soluções desenvolvidas neste capítulo, dedicamos esforços para apresentar resultados nessa categoria de vídeos, mais especificamente em sequências de vídeo naturais HD1080. No entanto, sequências de vídeos naturais HD720 e UHD4K também serão consideradas, sempre que possível, para avaliação dos modelos preditivos. É importante destacar que, como qualquer outro trabalho envolvendo aprendizado de máquina, os conjuntos de dados precisam ser divididos em três subconjuntos, conforme discutido na seção \ref{cap:2.2}: de treinamento, de teste e de predição. Visando construir um vasto conjunto de vídeos, independentes entre si, utilizamos todos os vídeos HD1080 disponíveis nas condições comuns de teste dos documentos \cite{bib:av2_avm}, \citet{bib:hevcctc} e \citet{bib:ietfnetvct}, para compor, respectivamente, os conjuntos de treino (sete sequências), de teste (sete sequências) e de predição (demais sequências). Como pode ser visto na Tabela \ref{tab:XVII}, fazem parte dos vídeos de predição 48 sequências, distribuídas entre as resoluções HD720, HD1080 e UHD4K. Como foi dito no capítulo \ref{cap:4}, o Apêndice \ref{apx:A} descreve com detalhes as sequências utilizadas. Na Tabela \ref{tab:XVII}, constam os nomes das sequências utilizadas em cada uma das fases de desenvolvimento das soluções propostas neste capítulo.

\input{TABLES/tab_xvii.tex}

\subsection{Algoritmos de Aprendizado de Máquina}
\label{cap:7.1.3}

No capítulo \ref{cap:4}, especificamos que a linguagem Python versão 3 foi utilizada para o desenvolvimento de algumas soluções apresentadas nesta tese, em particular as apresentadas no atual capítulo. Dentre essas soluções, está o treinamento de modelos preditivos gerados por algoritmos de aprendizado de máquina. Existem diversas ferramentas, desenvolvidas em Python, que possibilitam essa geração de modelos preditivos, dentre elas o pacote \textit{Scikit-Learn} \cite{bib:scikitlearn-site}. Esse pacote oferece um algoritmo para treinamento de árvores de decisão que permitem a classificação e a regressão de valores, denominado \textit{Classification and Regression Trees} (CART) \cite{bib:scikitlearn_cart}, baseado no trabalho de \citet{bib:livroCART}. Este algoritmo permite a manipulação de alguns hiperparâmetros, descritos na Tabela \ref{tab:XVIII}. Nesta tabela apresentamos os hiperparâmetros existentes no algoritmo CART e seus respectivos valores usados nas soluções propostas de transcodificação rápida com uso de modelos gerados pelo algoritmo CART. Na última coluna da Tabela \ref{tab:XVIII}, apresentamos a quantidade de variações existentes para cada hiperparâmetro, considerando os valores que utilizaremos. Logo, calculando-se o produto dessas variações, há um total de 9,5 milhões de modelos candidatos de aprendizado de máquina a serem treinados com este algoritmo. Observe que, em vários hiperparâmetros da Tabela \ref{tab:XVIII} que utilizam valores inteiros como entrada, consideramos um valor máximo de 25. A razão disso é a quantidade de atributos utilizados nos trabalhos deste capítulo, que é de 25, conforme consta na seção \ref{cap:7.3}.

\input{TABLES/tab_xviii.tex}

\subsection{Mensuração de Resultados}
\label{cap:7.1.4}

Na seção \ref{cap:2.4} discutimos as métricas estatísticas \textit{F1-Score} (Equação \ref{eq:6}) e AUC (Figura \ref{fig:8}) para avaliação dos treinamentos dos modelos preditivos gerados por algoritmos de aprendizado de máquina. O pacote \textit{scikit-learn} oferece meios de mensurar essas métricas, por meio do módulo ``\textit{sklearn.metrics}'', que permite utilizar as funções ``\textit{f1\_score}'' \cite{bib:scikitlearn_f1} e ``\textit{roc\_auc\_score}'' \cite{bib:scikitlearn_auc}. Essas duas funções possuem diversos parâmetros de utilização, conforme pode ser observado em documentação própria \cite{bib:scikitlearn_f1, bib:scikitlearn_auc}. Serão utilizados os valores padrões dessas funções, exceto por um único parâmetro: ``\textit{average}''. Por padrão, esse parâmetro avalia apenas os resultados positivos preditos pelo modelo treinado; no entanto, apesar dos modelos treinados pelas nossas propostas terem rótulos binários (ver mais na seção \ref{cap:7.3}), a relevância das respostas positivas tanto quanto as negativas possuem igual importância. Dessa forma, como é importante que as funções ``\textit{f1\_score}'' e ``\textit{roc\_auc\_score}'' avaliem ambas respostas do rótulo igualmente, o parâmetro ``\textit{average}'' deve ser configurado como ``\texttt{macro}''.

Em relação às métricas para comparação dos resultados de transcodificação rápida, empregamos os valores de TS (Equação \ref{eq:7}) e de BD-rate (Figura \ref{fig:9}), ambos já apresentados na seção \ref{cap:2.5}. Em relação à captura do tempo de processamento, valor importante para gerar o TS, usamos os valores informados pelo próprio software de referência do AV1, cujo tempo total da codificação é mensurado em milissegundos, posteriormente convertidos para segundos. Já no caso do BD-rate, utilizamos os valores de bitrate (em kilobits por segundo, kbps) e de PSNR-Y (em decibéis, dB).
